"""Configuration loading from YAML files and environment variables."""

from __future__ import annotations

import os
from pathlib import Path
from typing import Any

import yaml

CONFIG_DIR = Path.home() / ".argus-ops"
DEFAULT_CONFIG_PATH = CONFIG_DIR / "config.yaml"

DEFAULT_CONFIG: dict[str, Any] = {
    "ai": {
        "provider": "openai",
        "model": "gpt-4o-mini",
        "api_key_env": "OPENAI_API_KEY",
        "base_url": None,
        "temperature": 0.3,
        "max_tokens": 4096,
        "cost_limit_per_run": 0.50,
    },
    "targets": {
        "kubernetes": {
            "enabled": True,
            "kubeconfig": None,
            "context": None,
            "namespaces": [],
            "exclude_namespaces": ["kube-system", "kube-public", "kube-node-lease"],
        },
        "ssh_hosts": [],
        "docker_hosts": [],
        "prometheus": {
            "enabled": False,
            "url": "http://localhost:9090",
        },
    },
    "analyzers": {
        "resource": {
            "cpu_warning": 80,
            "cpu_critical": 95,
            "memory_warning": 85,
            "memory_critical": 95,
            "disk_warning": 80,
            "disk_critical": 90,
        },
        "pod_health": {
            "crashloop_restart_threshold": 5,
            "pending_timeout_minutes": 10,
        },
        "node_health": {
            "conditions_to_check": [
                "Ready",
                "MemoryPressure",
                "DiskPressure",
                "PIDPressure",
            ],
        },
    },
    "logging": {
        "level": "INFO",
    },
}


def load_config(config_path: str | Path | None = None) -> dict[str, Any]:
    """Load configuration with priority: env vars > YAML file > defaults.

    Args:
        config_path: Path to YAML config file. If None, uses ~/.argus-ops/config.yaml.

    Returns:
        Merged configuration dictionary.
    """
    config = _deep_copy_dict(DEFAULT_CONFIG)

    path = Path(config_path) if config_path else DEFAULT_CONFIG_PATH
    if path.exists():
        with open(path) as f:
            file_config = yaml.safe_load(f) or {}
        config = _deep_merge(config, file_config)

    _apply_env_overrides(config)
    return config


def create_default_config(path: Path | None = None) -> Path:
    """Create a default configuration file.

    Args:
        path: Where to create the config. Defaults to ~/.argus-ops/config.yaml.

    Returns:
        Path to the created config file.
    """
    target = path or DEFAULT_CONFIG_PATH
    target.parent.mkdir(parents=True, exist_ok=True)
    with open(target, "w") as f:
        yaml.dump(
            DEFAULT_CONFIG,
            f,
            default_flow_style=False,
            sort_keys=False,
            allow_unicode=True,
        )
    return target


def _apply_env_overrides(config: dict[str, Any]) -> None:
    """Apply ARGUS_OPS_* environment variable overrides."""
    env_mappings = {
        "ARGUS_OPS_AI_PROVIDER": ("ai", "provider"),
        "ARGUS_OPS_AI_MODEL": ("ai", "model"),
        "ARGUS_OPS_AI_BASE_URL": ("ai", "base_url"),
        "ARGUS_OPS_LOG_LEVEL": ("logging", "level"),
    }
    for env_var, (section, key) in env_mappings.items():
        value = os.environ.get(env_var)
        if value:
            if section not in config:
                config[section] = {}
            config[section][key] = value


def _deep_merge(base: dict, override: dict) -> dict:
    """Recursively merge override dict into base dict."""
    result = base.copy()
    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = _deep_merge(result[key], value)
        else:
            result[key] = value
    return result


def _deep_copy_dict(d: dict) -> dict:
    """Deep copy a nested dict structure."""
    result = {}
    for key, value in d.items():
        if isinstance(value, dict):
            result[key] = _deep_copy_dict(value)
        elif isinstance(value, list):
            result[key] = value.copy()
        else:
            result[key] = value
    return result


def generate_default_yaml() -> str:
    """Return a commented default config.yaml as a string."""
    return """\
# Argus-Ops Configuration
# Generated by: argus-ops config init
# Docs: https://github.com/mason5052/argus-ops

# AI Provider Settings
ai:
  # Provider: openai, anthropic, ollama, azure, bedrock, gemini, etc.
  # LiteLLM supports 100+ providers via the same interface.
  provider: openai

  # Model name (provider-specific)
  # OpenAI:    gpt-4o-mini, gpt-4o
  # Anthropic: claude-haiku-4-5-20251001, claude-sonnet-4-6
  # Ollama:    ollama/llama3.2, ollama/mistral
  model: gpt-4o-mini

  # Name of the environment variable containing the API key
  # Set: export OPENAI_API_KEY=sk-...
  api_key_env: OPENAI_API_KEY

  # Custom base URL for self-hosted or Ollama endpoints
  # Ollama example: http://localhost:11434
  base_url: null

  temperature: 0.3
  max_tokens: 4096

  # Stop if AI costs exceed this amount per run (USD)
  cost_limit_per_run: 0.50

# Infrastructure Targets
targets:
  kubernetes:
    enabled: true
    # Path to kubeconfig file (null = default ~/.kube/config)
    kubeconfig: null
    # Kubernetes context to use (null = current context)
    context: null
    # Specific namespaces to scan (empty = scan all except excluded)
    namespaces: []
    # Namespaces to exclude
    exclude_namespaces:
      - kube-system
      - kube-public
      - kube-node-lease

# Analyzer Thresholds
analyzers:
  resource:
    cpu_warning: 80
    cpu_critical: 95
    memory_warning: 85
    memory_critical: 95
    disk_warning: 80
    disk_critical: 90
  pod_health:
    crashloop_restart_threshold: 5
    pending_timeout_minutes: 10

# Logging
logging:
  level: WARNING  # DEBUG, INFO, WARNING, ERROR
"""
